============================= test session starts ==============================
platform darwin -- Python 3.9.6, pytest-7.4.4, pluggy-1.3.0
rootdir: /Users/fanshaomin/Documents/learning/dlsyscourse/hw0
plugins: anyio-4.0.0
collected 6 items / 5 deselected / 1 selected

tests/test_simple_ml.py 50
[ 0.00622559 -0.00778112  0.00155551 -0.00811768  0.01015398 -0.0020303
 -0.00086553  0.00108337 -0.00021777  0.00046243 -0.00057953  0.00011525
 -0.00617342  0.0077163  -0.00154263]
(15,)
[[0. 0. 0.]
 [0. 0. 0.]
 [0. 0. 0.]
 [0. 0. 0.]
 [0. 0. 0.]]
(50, 5)
(5, 3)
[[ 0.00622559 -0.00778112  0.00155551]
 [-0.00811768  0.01015398 -0.0020303 ]
 [-0.00086553  0.00108337 -0.00021777]
 [ 0.00046243 -0.00057953  0.00011525]
 [-0.00617342  0.0077163  -0.00154263]]
[[-3.60618105e-03  4.50920038e-03 -9.04267594e-04]
 [-1.62481624e-02  2.03156417e-02 -4.06146962e-03]
 [-1.42511543e-02  1.78248033e-02 -3.56497943e-03]
 [-4.45609600e-03  5.58033421e-03 -1.11608141e-03]
 [-3.63032672e-02  4.53826811e-02 -9.07342881e-03]
 [-1.76258874e-02  2.20281584e-02 -4.40444532e-03]
 [-1.04928007e-04  1.35726175e-04 -2.50196571e-05]
 [-8.36730095e-03  1.04702144e-02 -2.09480034e-03]
 [ 1.05246101e-02 -1.31716168e-02  2.63464557e-03]
 [ 7.33659771e-03 -9.17610277e-03  1.83498263e-03]
 [-8.64541482e-03  1.08096921e-02 -2.15979392e-03]
 [ 3.81087823e-03 -4.76120774e-03  9.51824028e-04]
 [-2.45753275e-03  3.07016736e-03 -6.11600597e-04]
 [ 9.59130582e-03 -1.19986977e-02  2.39933824e-03]
 [-5.49055051e-04  6.91157586e-04 -1.38878023e-04]
 [ 2.81571289e-03 -3.52663632e-03  7.06258796e-04]
 [-2.48674151e-02  3.10917402e-02 -6.21564360e-03]
 [-4.61492216e-03  5.77924492e-03 -1.15506158e-03]
 [-1.43620663e-02  1.79593296e-02 -3.59161625e-03]
 [ 3.44910682e-04 -4.28225431e-04  8.33574705e-05]
 [ 3.14544924e-02 -3.93285239e-02  7.86371669e-03]
 [ 7.85413302e-03 -9.82350699e-03  1.96360014e-03]
 [ 7.55485664e-03 -9.43970741e-03  1.88658383e-03]
 [-7.96875978e-03  9.96658426e-03 -1.99307430e-03]
 [ 1.59111348e-02 -1.98973833e-02  3.97703482e-03]
 [-1.20426434e-03  1.50371016e-03 -3.03061086e-04]
 [-4.64690843e-03  5.81095275e-03 -1.16105447e-03]
 [ 6.64195985e-03 -8.29827402e-03  1.65874099e-03]
 [-2.74135529e-02  3.42668461e-02 -6.85118994e-03]
 [ 1.45641643e-02 -1.82068580e-02  3.63959163e-03]
 [-1.34629776e-02  1.68406563e-02 -3.36594043e-03]
 [-1.01692695e-02  1.27191174e-02 -2.54113352e-03]
 [-1.19799949e-02  1.49896904e-02 -2.99849434e-03]
 [ 1.33058825e-02 -1.66426980e-02  3.32855753e-03]
 [ 8.48770955e-03 -1.06039314e-02  2.11912396e-03]
 [ 1.10434118e-02 -1.38095453e-02  2.76208931e-03]
 [ 4.62667472e-03 -5.79103134e-03  1.16032931e-03]
 [-1.09215482e-02  1.36433981e-02 -2.72668808e-03]
 [-1.39531924e-02  1.74436553e-02 -3.48654123e-03]
 [-1.52964953e-02  1.91231233e-02 -3.82559828e-03]
 [-4.95574702e-03  6.19304162e-03 -1.23969509e-03]
 [-8.49487022e-03  1.06155741e-02 -2.12140771e-03]
 [ 8.02551129e-03 -1.00266248e-02  2.00368248e-03]
 [-1.43715786e-03  1.79317302e-03 -3.60268559e-04]
 [ 6.99314687e-03 -8.74530891e-03  1.74880047e-03]
 [ 1.14988598e-04 -1.41258130e-04  2.82704654e-05]
 [ 2.93885498e-03 -3.67906291e-03  7.36183525e-04]
 [-9.45841605e-03  1.18300021e-02 -2.36340418e-03]
 [ 1.14147682e-03 -1.42973471e-03  2.86352051e-04]
 [-1.20460697e-02  1.50675664e-02 -3.01331797e-03]]
[1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 1 1 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 0
 1 1 1 1 1 0 1 0 0 0 1 0 1]
[1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 1 1 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 0
 1 1 1 1 1 0 1 0 0 0 1 0 1]
[[1]
 [0]
 [2]
 [0]
 [0]
 [1]
 [2]
 [1]
 [1]
 [1]
 [0]
 [0]
 [2]
 [0]
 [0]
 [2]
 [1]
 [2]
 [2]
 [0]
 [2]
 [2]
 [0]
 [2]
 [1]
 [0]
 [1]
 [2]
 [1]
 [1]
 [0]
 [1]
 [1]
 [1]
 [2]
 [0]
 [1]
 [1]
 [0]
 [1]
 [2]
 [0]
 [1]
 [2]
 [1]
 [2]
 [1]
 [2]
 [1]
 [2]]
1.0984927
loss: 1.10
[[ 0.00619771 -0.00789249  0.00169476]
 [-0.00809229  0.01006611 -0.00196782]
 [-0.00082087  0.00108982 -0.00026887]
 [ 0.00038577 -0.00052944  0.00014182]
 [-0.00615425  0.00772688 -0.00157238]]
F

=================================== FAILURES ===================================
________________________ test_softmax_regression_epoch _________________________

    def test_softmax_regression_epoch():
        # test numeical gradient
        np.random.seed(0)
        X = np.random.randn(50,5).astype(np.float32)
        y = np.random.randint(3, size=(50,)).astype(np.uint8)
        Theta = np.zeros((5,3), dtype=np.float32)
        dTheta = -nd.Gradient(lambda Th : softmax_loss(X@Th.reshape(5,3),y))(Theta)
        softmax_regression_epoch(X,y,Theta,lr=1.0,batch=50)
>       np.testing.assert_allclose(dTheta.reshape(5,3), Theta, rtol=1e-4, atol=1e-4)
E       AssertionError: 
E       Not equal to tolerance rtol=0.0001, atol=0.0001
E       
E       Mismatched elements: 15 / 15 (100%)
E       Max absolute difference: 0.13991101
E       Max relative difference: inf
E        x: array([[-0.025259, -0.114651,  0.139911],
E              [ 0.022913, -0.084774,  0.06186 ],
E              [ 0.043868,  0.00743 , -0.051293],...
E        y: array([[0., 0., 0.],
E              [0., 0., 0.],
E              [0., 0., 0.],...

tests/test_simple_ml.py:91: AssertionError
=========================== short test summary info ============================
FAILED tests/test_simple_ml.py::test_softmax_regression_epoch - AssertionError: 
======================= 1 failed, 5 deselected in 0.31s ========================
